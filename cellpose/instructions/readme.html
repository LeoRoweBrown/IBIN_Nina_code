<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<header>
<h1 class="title">Cellpose and segmentation instructions</h1>
</header>
<h1>Annotation of dataset with VAST</h1>
<figure>
<img src="file:///C:/Users/lnr19/AppData/Local/Temp/msohtmlclip1/01/clip_image002.jpg" />
</figure>
<p>Firstly, import the image stack for segmentation which must be 8-bit. You will be prompted on import settings (it’s self-explanatory).</p>
<figure>
<img src="file:///C:/Users/lnr19/AppData/Local/Temp/msohtmlclip1/01/clip_image004.jpg" />
</figure>
<p>Once you import, add a new segmentation layer and you have the option to add 16 empty segments.</p>
<figure>
<img src="file:///C:/Users/lnr19/AppData/Local/Temp/msohtmlclip1/01/clip_image006.jpg" />
</figure>
<p>Use - and + keys to change size of brush, hold right-click while you paint to erase. If you change the plane (up and down arrow keys) while painting (holding left click or drawing with pen) you can paint the other planes up to the maximum paint depth. I tend to just do everything plate by plane.</p>
<p>Ticking fill allows you to draw a boundary and it automatically fills the inside.</p>
<figure>
<img src="file:///C:/Users/lnr19/AppData/Local/Temp/msohtmlclip1/01/clip_image008.jpg" />
</figure>
<p>You can freely change the brightness of the image layer or the segmentation layer as you go.</p>
<figure>
<img src="file:///C:/Users/lnr19/AppData/Local/Temp/msohtmlclip1/01/clip_image010.jpg" />
</figure>
<p>If you want to segment in 3D e.g. for Stardist or intend to also train the model on XZ and YZ slices, it can be a good idea to segment in the different views (under view menu) </p>
<figure>
<img src="file:///C:/Users/lnr19/AppData/Local/Temp/msohtmlclip1/01/clip_image012.jpg" />
</figure>
<figure>
<img src="file:///C:/Users/lnr19/AppData/Local/Temp/msohtmlclip1/01/clip_image014.jpg" />
</figure>
<p>Go through the full stack, changing the current slice with up and down arrow keys, annotating with unique segments as you go and adding new ones as necessary.</p>
<p>Once everything has been annotated Simply export as TIFF to get the XY slices of the segmentation/annotation. Use FIJI/ImageJ load these and reslice to get XZ and YZ slices.</p>
<p></p>
<h1>Install Cellpose</h1>
<p>I don’t think the order matters, but if you want Cellpose to use GPU you need to follow install instructions for pytorch (I’m assuming basic knowledge of python package installing here)</p>
<p><a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/
</a></p>
<pre><code>pip3 install cellpose
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</code></pre>
<h1>Run Cellpose training</h1>
<p>Note: Cellpose 3 differs from Cellpose 2 in that the train function is now separated into a model to identify size in the data, train_size, and the main model to find the segmentation, train_seg—I only use train_seg.</p>
<p>Cellpose will train a model on a given object size and the pretrained models use 30 px for cells and 17 px for nuclei. When the model is evaluated, the data is scaled based on the diameter of your objects, given by mean_diam. I’m still slightly unclear on this. See: <a href="https://github.com/MouseLand/cellpose/issues/632">https://github.com/MouseLand/cellpose/issues/632
</a></p>
<p>An example of training a Cellpose model is shown in the <a href="https://github.com/LeoRoweBrown/IBIN_Nina_code/blob/main/cellpose/training_new_cellpose.ipynb">training_new_cellpose.ipynb</a> notebook</p>
<h1>Run Cellpose segmentation</h1>
<p>An example of running a Cellpose model for a single volume (multipage TIFF stack) is shown in the <a href="https://github.com/LeoRoweBrown/IBIN_Nina_code/blob/main/cellpose/segment_single_vol.ipynb">segment_single_vol.ipynb</a> notebook. </p>
<p>An example of running a Cellpose model for an entire OPM dataset (TIFF sequence in a folder) is shown in the <a href="https://github.com/LeoRoweBrown/IBIN_Nina_code/blob/main/cellpose/segment.ipynb">segment.ipynb</a> notebook.</p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
<p></p>
</body>
</html>
